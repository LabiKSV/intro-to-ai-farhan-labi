{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a71a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e23c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046ea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2bd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('C:/Users/farha/Desktop/uni stage 3/Introduction to AI/COURSEWORK/Github/intro-to-ai-farhan-labi/covid_19_indonesia_time_series_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62a3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86e4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set date as index this just makes the df easier to work with\n",
    "df_regression = df_regression.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6c454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the NA values that are in int columns, fill them with medians \n",
    "med_gf_nc = df_regression['Growth Factor of New Cases'].median()\n",
    "med_gf_nd = df_regression['Growth Factor of New Deaths'].median()\n",
    "med_tot_uv = df_regression['Total Urban Villages'].median()\n",
    "med_tot_rv = df_regression['Total Rural Villages'].median()\n",
    "med_tot_c = df_regression['Total Cities'].median()\n",
    "\n",
    "df_regression['Growth Factor of New Cases'] = df_regression['Growth Factor of New Cases'].fillna(med_gf_nc)\n",
    "\n",
    "df_regression['Growth Factor of New Deaths'] = df_regression['Growth Factor of New Deaths'].fillna(med_gf_nd)\n",
    "\n",
    "df_regression['Total Urban Villages'] = df_regression['Total Urban Villages'].fillna(med_tot_uv)\n",
    "\n",
    "df_regression['Total Rural Villages'] = df_regression['Total Rural Villages'].fillna(med_tot_rv)\n",
    "\n",
    "df_regression['Total Cities'] = df_regression['Total Cities'].fillna(med_tot_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b24b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can drop the following columns, because either they are redundant, have nothing in them (all rows NA) or non relevant\n",
    "df_regression = df_regression.drop(columns=['City or Regency', 'Province', 'Island', 'Time Zone', 'Special Status', 'Location ISO Code',\n",
    "                                           'Location Level', 'Country', 'Continent', 'Location', 'Case Fatality Rate', 'Case Recovered Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4a5c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Cases                        int64\n",
      "New Deaths                       int64\n",
      "New Recovered                    int64\n",
      "New Active Cases                 int64\n",
      "Total Cases                      int64\n",
      "Total Deaths                     int64\n",
      "Total Recovered                  int64\n",
      "Total Active Cases               int64\n",
      "Total Regencies                  int64\n",
      "Total Cities                   float64\n",
      "Total Districts                  int64\n",
      "Total Urban Villages           float64\n",
      "Total Rural Villages           float64\n",
      "Area (km2)                       int64\n",
      "Population                       int64\n",
      "Population Density             float64\n",
      "Longitude                      float64\n",
      "Latitude                       float64\n",
      "New Cases per Million          float64\n",
      "Total Cases per Million        float64\n",
      "New Deaths per Million         float64\n",
      "Total Deaths per Million       float64\n",
      "Total Deaths per 100rb         float64\n",
      "Growth Factor of New Cases     float64\n",
      "Growth Factor of New Deaths    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Check datatypes of all remaining columns in dataframe\n",
    "print(df_regression.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4165ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all columns to float32 unless it is float64 (for regression)\n",
    "#It is already float 64\n",
    "df_regression[['New Cases', 'New Deaths', 'New Recovered', 'New Active Cases', 'Total Cases',\n",
    "              'Total Deaths', 'Total Recovered', 'Total Active Cases',\n",
    "              'Total Regencies', 'Total Districts', 'Area (km2)', 'Population']] = df_regression[['New Cases', 'New Deaths', 'New Recovered', 'New Active Cases', 'Total Cases',\n",
    "              'Total Deaths', 'Total Recovered', 'Total Active Cases',\n",
    "              'Total Regencies', 'Total Districts', 'Area (km2)', 'Population']].astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9271c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers function from exercises\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) \n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13f67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fbbe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 21759\n",
      "After: 15844\n"
     ]
    }
   ],
   "source": [
    "#Removing outliers for new active cases\n",
    "print(\"Before: {}\".format(len(df_regression)))\n",
    "remove_outliers(df_regression, 'New Active Cases', 2)\n",
    "print(\"After: {}\".format(len(df_regression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bd4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = to_xy(df_regression, 'New Active Cases')\n",
    "#Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f468a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalize dataset using min max\n",
    "# sc_x = StandardScaler()\n",
    "# sc_x.fit(X_train)\n",
    "# #Transform X\n",
    "# X_train = sc_x.transform(X_train)\n",
    "# X_test = sc_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f526805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minmax give a larger range of numbers so may help into back propogation when training\n",
    "#Minmax\n",
    "mms_x = MinMaxScaler()\n",
    "#Fit x y\n",
    "mms_x.fit(X_train)\n",
    "#Transform X\n",
    "X_train = mms_x.transform(X_train)\n",
    "X_test = mms_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ff3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 3D input dataset\n",
    "#This is because LSTM takes a 3D input for back propagation\n",
    "#Came from https://towardsdatascience.com/predictive-analysis-rnn-lstm-and-gru-to-predict-water-consumption-e6bb3c2b4b02\n",
    "def create_dataset(X, y, steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-steps):\n",
    "        v = X[i:i+steps]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f79b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes predictions based on the last x number of data\n",
    "#Since the dataset is large, I chose to predict over a large amount of steps\n",
    "steps = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c03e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (3937, 24, 24)\n",
      "y_train.shape:  (11859, 1)\n",
      "X_test.shape:  (3937, 24, 24)\n",
      "y_test.shape:  (11859, 1)\n",
      "[[[1.47492625e-04 0.00000000e+00 1.91546424e-04 ... 5.21512411e-04\n",
      "   2.71739140e-02 2.70270277e-02]\n",
      "  [1.47492625e-04 0.00000000e+00 7.34261237e-04 ... 3.60169500e-01\n",
      "   1.81521736e-02 2.70270277e-02]\n",
      "  [3.59882019e-03 1.25156448e-03 8.55574012e-03 ... 1.04302485e-02\n",
      "   7.39130471e-03 2.70270277e-02]\n",
      "  ...\n",
      "  [2.54277289e-02 5.63204009e-03 2.21874602e-02 ... 3.84419829e-01\n",
      "   1.92391314e-02 6.08108118e-02]\n",
      "  [8.84955807e-05 0.00000000e+00 1.91546424e-04 ... 3.65058682e-03\n",
      "   1.63043477e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.25945264e-04\n",
      "   1.08695654e-02 2.70270277e-02]]\n",
      "\n",
      " [[1.47492625e-04 0.00000000e+00 7.34261237e-04 ... 3.60169500e-01\n",
      "   1.81521736e-02 2.70270277e-02]\n",
      "  [3.59882019e-03 1.25156448e-03 8.55574012e-03 ... 1.04302485e-02\n",
      "   7.39130471e-03 2.70270277e-02]\n",
      "  [0.00000000e+00 6.25782239e-04 0.00000000e+00 ... 5.21512411e-04\n",
      "   0.00000000e+00 2.70270277e-02]\n",
      "  ...\n",
      "  [8.84955807e-05 0.00000000e+00 1.91546424e-04 ... 3.65058682e-03\n",
      "   1.63043477e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.25945264e-04\n",
      "   1.08695654e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.17340300e-03\n",
      "   0.00000000e+00 2.70270277e-02]]\n",
      "\n",
      " [[3.59882019e-03 1.25156448e-03 8.55574012e-03 ... 1.04302485e-02\n",
      "   7.39130471e-03 2.70270277e-02]\n",
      "  [0.00000000e+00 6.25782239e-04 0.00000000e+00 ... 5.21512411e-04\n",
      "   0.00000000e+00 2.70270277e-02]\n",
      "  [5.89970514e-05 0.00000000e+00 6.38488054e-05 ... 5.21512411e-04\n",
      "   1.63043488e-03 2.70270277e-02]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.25945264e-04\n",
      "   1.08695654e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.17340300e-03\n",
      "   0.00000000e+00 2.70270277e-02]\n",
      "  [8.84955807e-05 0.00000000e+00 0.00000000e+00 ... 8.14863108e-03\n",
      "   4.13043471e-03 2.70270277e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.94985250e-04 6.25782239e-04 6.38488054e-05 ... 9.10691023e-02\n",
      "   5.43478280e-02 2.70270277e-02]\n",
      "  [1.50442484e-03 0.00000000e+00 7.02336838e-04 ... 1.49934820e-03\n",
      "   2.05434784e-02 2.70270277e-02]\n",
      "  [1.47492625e-03 6.88360445e-03 0.00000000e+00 ... 5.93220396e-03\n",
      "   5.00000035e-03 2.70270277e-02]\n",
      "  ...\n",
      "  [6.51917420e-03 5.63204009e-03 3.95862572e-03 ... 1.05345502e-01\n",
      "   1.27173914e-02 2.43243247e-01]\n",
      "  [2.44837767e-03 0.00000000e+00 4.24594572e-03 ... 7.58148655e-02\n",
      "   1.03260875e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   1.08695654e-02 2.70270277e-02]]\n",
      "\n",
      " [[1.50442484e-03 0.00000000e+00 7.02336838e-04 ... 1.49934820e-03\n",
      "   2.05434784e-02 2.70270277e-02]\n",
      "  [1.47492625e-03 6.88360445e-03 0.00000000e+00 ... 5.93220396e-03\n",
      "   5.00000035e-03 2.70270277e-02]\n",
      "  [3.83480830e-04 1.25156448e-03 2.23470823e-04 ... 5.41069126e-03\n",
      "   1.28260870e-02 5.40540554e-02]\n",
      "  ...\n",
      "  [2.44837767e-03 0.00000000e+00 4.24594572e-03 ... 7.58148655e-02\n",
      "   1.03260875e-02 2.70270277e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   1.08695654e-02 2.70270277e-02]\n",
      "  [1.17994103e-04 0.00000000e+00 0.00000000e+00 ... 6.51890528e-04\n",
      "   1.07608698e-02 0.00000000e+00]]\n",
      "\n",
      " [[1.47492625e-03 6.88360445e-03 0.00000000e+00 ... 5.93220396e-03\n",
      "   5.00000035e-03 2.70270277e-02]\n",
      "  [3.83480830e-04 1.25156448e-03 2.23470823e-04 ... 5.41069126e-03\n",
      "   1.28260870e-02 5.40540554e-02]\n",
      "  [2.59587029e-03 1.25156448e-03 3.12859146e-03 ... 6.64276406e-02\n",
      "   5.76086948e-03 1.81081090e-02]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   1.08695654e-02 2.70270277e-02]\n",
      "  [1.17994103e-04 0.00000000e+00 0.00000000e+00 ... 6.51890528e-04\n",
      "   1.07608698e-02 0.00000000e+00]\n",
      "  [2.65486725e-03 3.12891114e-03 4.15017223e-03 ... 1.03520215e-01\n",
      "   7.39130471e-03 6.75675720e-02]]]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_dataset(X_test, y_test, steps)\n",
    "X_train, y_train = create_dataset(X_train, y_train, steps)\n",
    "\n",
    "print('X_train.shape: ', X_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_train.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4512e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and fit LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape = [X_train.shape[1], X_train.shape[2]], return_sequences=True)) #Layer1\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64)) #Layer 2\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid')) #Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40fa03d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "371/371 - 5s - loss: 27561.0527\n",
      "Epoch 2/20\n",
      "371/371 - 5s - loss: 27559.8828\n",
      "Epoch 3/20\n",
      "371/371 - 5s - loss: 27559.8613\n",
      "Epoch 4/20\n",
      "371/371 - 5s - loss: 27559.8828\n",
      "Epoch 5/20\n",
      "371/371 - 5s - loss: 27559.8926\n",
      "Epoch 6/20\n",
      "371/371 - 6s - loss: 27559.8691\n",
      "Epoch 7/20\n",
      "371/371 - 5s - loss: 27559.8633\n",
      "Epoch 8/20\n",
      "371/371 - 5s - loss: 27559.8691\n",
      "Epoch 9/20\n",
      "371/371 - 5s - loss: 27559.8789\n",
      "Epoch 10/20\n",
      "371/371 - 5s - loss: 27559.8789\n",
      "Epoch 11/20\n",
      "371/371 - 5s - loss: 27559.8711\n",
      "Epoch 12/20\n",
      "371/371 - 5s - loss: 27559.8574\n",
      "Epoch 13/20\n",
      "371/371 - 6s - loss: 27559.8730\n",
      "Epoch 14/20\n",
      "371/371 - 6s - loss: 27559.8789\n",
      "Epoch 15/20\n",
      "371/371 - 7s - loss: 27559.8613\n",
      "Epoch 16/20\n",
      "371/371 - 6s - loss: 27559.8613\n",
      "Epoch 17/20\n",
      "371/371 - 5s - loss: 27559.8730\n",
      "Epoch 18/20\n",
      "371/371 - 5s - loss: 27559.8613\n",
      "Epoch 19/20\n",
      "371/371 - 5s - loss: 27559.8730\n",
      "Epoch 20/20\n",
      "371/371 - 5s - loss: 27559.8652\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 24, 64)            22784     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 55,873\n",
      "Trainable params: 55,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "test = model.fit(X_train, y_train, verbose=2, epochs=20)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9711f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b65df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3937, 1)\n",
      "Shape: (3937, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: {}\".format(y_pred.shape))\n",
    "print(\"Shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "268fe9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final RMSE = 177.65662\n"
     ]
    }
   ],
   "source": [
    "print(\"final RMSE =\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
